{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"24BAD069 - MIDHUN P - ML Experiment 3 - Scenario 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daebb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
    "\n",
    "# Display the first few records to verify data loading\n",
    "print(df.head(3))\n",
    "\n",
    "# Define the target variable 'final_score' by averaging scores from three subjects\n",
    "df[\"final_score\"] = (df[\"math score\"] + df[\"reading score\"] + df[\"writing score\"]) / 3\n",
    "\n",
    "print(\"Done\")\n",
    "   \n",
    "# Convert categorical variables into numerical format using Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "df['parent_edu_level'] = encoder.fit_transform(df[\"parental level of education\"])\n",
    "df['test_prep'] = encoder.fit_transform(df['test preparation course'])\n",
    "\n",
    "# Verify the encoding process by printing sample values\n",
    "print(\"Encoded parental education levels:\")\n",
    "print(df['parent_edu_level'].head(3))\n",
    "\n",
    "print(\"Encoded test preparation course:\")\n",
    "print(df['test_prep'].head(3))\n",
    "\n",
    "# Generate synthetic data for study hours, attendance, and sleep hours\n",
    "n = len(df)\n",
    "df['study_hours'] = np.random.randint(1, 11, size=n)\n",
    "df['attendance'] = np.random.uniform(50, 100, size=n)\n",
    "df['sleep_hours'] = np.random.uniform(4, 10, size=n)\n",
    "\n",
    "# Display the first few values of the synthetic features\n",
    "print(df['study_hours'].head(10))\n",
    "print()\n",
    "print(df['attendance'].head(10))\n",
    "print()\n",
    "print(df['sleep_hours'].head(10))\n",
    "print()\n",
    "\n",
    "# Select features and target variable for the model\n",
    "features = ['study_hours', 'attendance', 'parent_edu_level', 'test_prep', 'sleep_hours']\n",
    "X = df[features]\n",
    "y = df[\"final_score\"]  \n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Handle missing values using mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "y_imputed = imputer.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_imputed, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict outcomes on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate model performance using MSE, RMSE, and R-squared metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# Display the regression coefficients for feature importance analysis\n",
    "coefficients = pd.DataFrame(model.coef_.flatten(), X.columns, columns=['Coefficient'])\n",
    "print(\"Regression Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Perform Recursive Feature Elimination (RFE) to select top 3 features\n",
    "rfe = RFE(model, n_features_to_select=3)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "print(f\"Selected Features by RFE: {X.columns[rfe.support_]}\")\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "# Apply Ridge Regression (L2 Regularization)\n",
    "ridge_model = Ridge(alpha=1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "print(f\"Ridge Regression MSE: {ridge_mse}\")\n",
    "\n",
    "# Apply Lasso Regression (L1 Regularization)\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "print(f\"Lasso Regression MSE: {lasso_mse}\")\n",
    "\n",
    "print()\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "# Plot Actual vs. Predicted values\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_test, y_pred, color='blue', label='Predicted vs Actual')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.xlabel('Actual Exam Scores')\n",
    "plt.ylabel('Predicted Exam Scores')\n",
    "plt.title('Predicted vs Actual Exam Scores')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature coefficients using a bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(features, model.coef_.flatten(), color='orange')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Magnitude')\n",
    "plt.title('Feature Coefficient Magnitude Comparison')\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Residual Distribution')\n",
    "plt.xlabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190cf6a8",
   "metadata": {},
   "source": [
    "\n",
    "# Scenario 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a737aebb",
   "metadata": {},
   "source": [
    "\n",
    "24BAD069 - MIDHUN P - scenairo 2- exp -3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aba658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Import required Python libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 2: Load and clean the Auto MPG dataset\n",
    "df = pd.read_csv(\"auto-mpg.csv\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['horsepower'] = imputer.fit_transform(df[['horsepower']])\n",
    "df['mpg'] = imputer.fit_transform(df[['mpg']])\n",
    "\n",
    "X = df[['horsepower']].values  \n",
    "y = df['mpg'].values  \n",
    "print(\"Done\")\n",
    "  \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "degrees = [2, 3, 4]\n",
    "models = {}\n",
    "for degree in degrees:\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    models[degree] = model\n",
    "    \n",
    "    y_pred = model.predict(X_test_poly)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Degree {degree} Polynomial Regression:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"R² Score: {r2}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "for degree in degrees:\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    ridge_model = Ridge(alpha=1)\n",
    "    ridge_model.fit(X_train_poly, y_train)\n",
    "\n",
    "    y_pred_ridge = ridge_model.predict(X_test_poly)\n",
    "    \n",
    "    mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "    rmse_ridge = np.sqrt(mse_ridge)\n",
    "    r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "    print(f\"Ridge Regression (Degree {degree}):\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse_ridge}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse_ridge}\")\n",
    "    print(f\"R² Score: {r2_ridge}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X, y, color='blue', label='Actual Data')\n",
    "x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "x_range_scaled = scaler.transform(x_range)\n",
    "\n",
    "for degree in degrees:\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_range_poly = poly.fit_transform(x_range_scaled)\n",
    "    y_range_pred = models[degree].predict(X_range_poly)\n",
    "    \n",
    "    plt.plot(x_range, y_range_pred, label=f'Degree {degree} Polynomial')\n",
    "\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('MPG')\n",
    "plt.title('Polynomial Regression: MPG vs Horsepower')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for degree in degrees:\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    model = models[degree]\n",
    "    train_pred = model.predict(X_train_poly)\n",
    "    test_pred = model.predict(X_test_poly)\n",
    "    \n",
    "    train_errors.append(np.sqrt(mean_squared_error(y_train, train_pred)))\n",
    "    test_errors.append(np.sqrt(mean_squared_error(y_test, test_pred)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, train_errors, label='Training Error', marker='o')\n",
    "plt.plot(degrees, test_errors, label='Testing Error', marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training vs Testing Error Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "train_errors_all = []\n",
    "test_errors_all = []\n",
    "\n",
    "for degree in range(1, 5):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train_poly)\n",
    "    test_pred = model.predict(X_test_poly)\n",
    "\n",
    "    train_errors_all.append(np.sqrt(mean_squared_error(y_train, train_pred)))\n",
    "    test_errors_all.append(np.sqrt(mean_squared_error(y_test, test_pred)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 5), train_errors_all, label='Training Error', marker='o')\n",
    "plt.plot(range(1, 5), test_errors_all, label='Testing Error', marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Overfitting and Underfitting Demonstration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
